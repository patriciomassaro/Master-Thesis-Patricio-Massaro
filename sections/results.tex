
\section{Results and discussion}\label{sec:results}


For each dataset, the combination of the probabilistic degradation model and the SR model (from now on, a pipeline) was trained. 
Each pipeline has 3 main components: 
\begin{itemize}
    \item A generator, used to generate LR images similar to the target domain, from HR images coming from the source domain.
    \item A discriminator, used to distinguish between real and generated LR images.
    \item A SR model, used to super resolve the LR images generated by the generator or the real LR images coming from the target domain.
\end{itemize}

The pipeline trained on $\mathcal{D}_{\text{SF}-\text{SF}}$, using unpaired HR-LR pairs generated by applying the baseline degradation model described in \ref{fig:3-probabilistic-degradation-model} to the synthetic FOREST-2 images, will be referred to as the baseline pipeline.
While the employed degradation model is stochastic, it has known parameters. The objective is to observe how the GAN is able to imitate a known degradation model  in order to produce LR images.

The pipeline trained on $\mathcal{D}_{\text{SF}-\text{RF}}$, using unpaired HR-LR pairs of synthetic and real FOREST-2 images, will be referred to as the adapted pipeline.
In this case, the degradation model is unknown and the objective of the GAN is to to estimate it, generating LR versions of the synthetic FOREST images that come from the same distribution as the real FOREST images.

    \subsection{Source domain}

        This subsection will analyze the results from the experiments performed on the source domain.
        The process consists of degrading the synthetic HR FOREST images using the generator trained using adversarial learning and then super resolving it using the corresponding SR model from the pipeline.
        This is the equivalent of the black arrows flow described in fig. \ref{fig:3-GAN-degradation-model}. 
        As in this case the ground truth is known, the performance of the super resolution can be evaluated using metrics like PSNR and SSIM. 

        Fig. \ref{fig:5-source_domain_sample} shows the results of the baseline and the adapted pipeline, when applied to one sample from the source domain (a synthetic HR FOREST-2 image). 
        For comparison, a pipeline consisting of simple gaussian blurring + downscaling for degradation and bicubic upsampling for SR is also shown. 

        While the baseline kernel is very simple and the noise is more or less uniform across the image, the adapted kernel is more complex and the noise seems to be strongly correlated with the image intensity.
        It is important not to overinterpret this result, as the kernel and noise are estimated using overparametrized models, and multiple combinations of kernel and noise may produce similar results. 
        However, it is interesting to see that the adapted pipeline is able to estimate a more complex degradation model, which is closer to the real degradation model used in the target domain.

        The degraded LR images present considerable differences. While the baseline pipeline produces images very similar to gaussian blurring + downscaling, 
        the adapted pipeline produces much more blurry images with more noise, suggesting that FOREST-2 produces less resolution than what was initially expected. 
        This is also confirmed by calculating the PSNR between the LR image generated by each pipeline with the gaussian blurring + downscaling LR image, which yields worse results for the adapted pipeline.
        
        The super resolved produces by both pipelines yield better performance than bicubic interpolation, and they are very similar between them.
        This suggests that the super resolution model is able to recover the details lost during a more complex degradation processes, but there seems to be a limit to the amount of detail that can be recovered. 
        It is observed that even though the starting point is different ( baseline LR is less blurry than adapted LR), the final result is very similar.

        
        
        
        \begin{figure}[H]
            \centering
            \includegraphics[width=\textwidth]{Includes/5-source-prediction-sample.pdf}
            \caption{Applying different degradation models on an HR sample. 
                     The 2 most upper rows show the estimated degradation kernels and noise of each pipeline, the bicubic downsampling does not estimate a kernel or noise.
                     The degraded LR images from each model and a zoom is displayed on the two subsequent rows. 
                     In this case, the PSNR is calculated against the gaussian blurring + bicubic downsampling LR.
                     The synthetic FOREST-2 (ground truth) and the super resolved images, with a zoom, are displayed in the last 2 rows. 
                     The PSNR for each SR method is calculated against the HR synthetic FOREST-2.
            }
            \label{fig:5-source_domain_sample}
        \end{figure}


        In Figs \ref{fig:5-lr-images-fft.pdf} the frequency domain of the LR images is analyzed.
        By inspection of the FFTs, it is observed that the adapted-LR loses more information than the baseline-LR, as the log magnitude of the FFT get cut more close to the center.
        The baseline-LR FFT is very close to the gaussian blurring + bicubic upsampling FFT, suggesting that the baseline pipeline is able to mimic this known degradation model.

        \begin{figure}[H]
            \centering
            \includegraphics[scale=0.3]{Includes/5-lr-images-fft.pdf}
            \caption{Log mangnitude of the FFT for the LR images obtained by the pipelines and the gaussian blurring + bicubic upsampling.}
            \label{fig:5-lr-images-fft.pdf}
        \end{figure}

        The radial profile of the log magnitude of the FFT for the LR images shown in Fig. \ref{fig:5-lr-images-fft-comparison.pdf} confirmed what was observed previously.
        The adapted-LR image diminishes the high frequency components much more than the baseline-LR image with amplifications of -6dB in frequencies starting at 0.1 cycles per pixel, with a stable effect of -6dB from 0.3 to 0.7 cycles per pixel. 
        It is important to note that 0.1 cycles per pixel at a 210m GSD corresponds to a cycle frequency of 2100 $m^{-1}$, 0.3 cycles per pixel corresponds to 700 $m^-1$ and 0.7 cycles per pixel to 300 $m^{-1}$.
        This suggests that the degradation model from the real FOREST-2 images is more complex and loses more information than the baseline degradation model.
        An analysis for the whole validation dataset will be further discussed to verify that this behaviour is consistent across different scenes and conditions.


        \begin{figure}[H]
            \centering
            \includegraphics[scale=0.45]{Includes/5-lr-images-fft-comparison.pdf}
            \caption{(a) Radial profile of the log magnitude across spatial frequency of the LR images obtained by the pipelines and the gaussian blurring + bicubic downsampling model.
                     (b) Amplification in dB of each pipeline with respect to the gaussian blurring + bicubic downsampling.}
            \label{fig:5-lr-images-fft-comparison.pdf}
        \end{figure}

        When analyzing the super resolved images versus the ground truth in the frequency domain, a very similar frequency response is observed for both pipelines.
        Moreover, the SR images are able to stay above -3dB, a common threshsold used in the literature, up until 0.3 cycles per pixel, which correspond to 300$\frac{1}{m}$ when each pixel equals 70m.
        This suggests that the SR model in the adapted pipeline is able to recover the lost information at those frequencies due its more complex degradation model.
        Starting at 0.3 cycles per pixel, a decrease in amplification is observed for both pipelines, but more steeply for the adapted pipeline.
        This may be related to the fact that the adapted degradation model diminishes cycles at higher frequencies even more than the baseline degradation model. 
        A limit for the SR algorithm is also noted, even using an optimistic degradation model such as the baseline, the SR model is not able to recover higher frequencies with respect to the original, HR image.
        Even if it is slightly better than bicubic upsampling, the diminishing of the higher frequency components is dramatic.

        \begin{figure}[H]
            \centering
            \includegraphics[scale=0.5]{Includes/5-source-sr-fft-comparison.pdf}
            \caption{Frequency domain analysis of the SR images and the ground truth displayed in \ref{fig:5-source_domain_sample}.
                     In (a), the log of the magnitude of the FFT for the SR images and the ground truth is shown,
                     while in (b), the amplification of each SR image with respect to the ground truth is shown.}
            \label{fig:5-source-sr-fft-comparison}
        \end{figure}

        \subsubsection{Probabilistic degradation models comparison}

        In order to better understand the stochastic nature of the generator, a kernel was extracted 2000 times from the it using different realizations of the random variable $z_k$.
        The mean and standard deviation of the sampled kernels was then computed.
        It is important to note that the experiment configuration assumes that the kernel does not depend on the pixel content or position, resulting in one kernel per image.
        The results are shown in Fig. \ref{fig:5-source-kernel-mean-std}. 
        In order to make the standard deviation of each pixel comparable, its value is normalized by the mean value of the corresponding pixel. 
        This allows to express the standard deviation as a percentage of the mean corresponding pixel value.
        
        While the baseline and the adapted kernel have the maximum mean and std in the same pixel, the adapted one is much more spread out. 
        The baseline kernel is composed of a few pixels very close to each other.
        This suggests that the adapted kernel is more complex and spread out, while the baseline kernel is simpler and more concentrated.
        The result of this is that the adapted kernel produces more blurry images, as the kernel is more spread out, while the baseline kernel produces less blurry images, as the degradation is more concentrated.
        The figure also displays the benefits of the probabilistic degradation model.
        Using only one HR image, the generator is able to produce a wide variety of LR pairs. Allowing the training of SR models able to generalize better to the real world.

        \begin{figure}[H]
            \centering
            \includegraphics[width=\textwidth]{Includes/5-source-kernel-mean-std.pdf}
            \caption{Mean and standard deviation of the estimated kernels for the baseline and adapted degradation model, using 2000 realizations of $z_k$.
                     The standard deviation of each pixel is normalized by the corresponding mean value.
                     kernel pixels with mean lower than $10^{-4}$ are considered with 0 std for clarity in the plot.}
            \label{fig:5-source-kernel-mean-std}
        \end{figure}

        In the case of the noise, the experiment setup assumes that it depends on the pixel content and position.
        For that reason, two different characterizations were done. 
        First, The stochastic component of the noise will be assessed by computing the SNR between the clean image $I_{\text{LR}}^{\text{clean}}$ and the output of the noise module for one HR input and 2000 realizations of $z_n$.
        This shows again the benefits of a stochastic model, several LR versions of an HR image can be generated, enriching a training dataset.

        
        \begin{figure}[H]
            \centering
            \includegraphics[width=\textwidth]{Includes/5-source-noise-1-sample.pdf}
            \caption{Distribution of SNR values using $I_{\text{LR}}^{\text{clean}}$, product of the convolution of the kernel and $I_{\text{HR}}^{\text{clean}}$, and the noise module output for both pipelines.
                     The output noise is generated 2000 times, using different realizations of the random variable $z_n$ for each iteration and the same input image.
                    }
            \label{fig:5-source-noise-1-sample}
        \end{figure}
        

        Second, the signal-to-noise (SNR) ratio between the clean image $I_{\text{LR}}^{\text{clean}}$ and the output of the noise module of the generator will be computed one time for the whole validation dataset.
        An estimated density function of the SNR for each degradation model is shown in Fig. \ref{fig:5-source-noise-SNR}.
        The SNR is in general bigger when using the baseline model compared to the adapted one.
        This implies that in the output of the generator, the noise has more energy compared to the clean image when the target domain is composed of scenes coming from the FOREST-2 satellite. 
        The distribution of the noise can not be assessed using this method, but it was observed in Fig. \ref{fig:5-source-domain-comparison} that it seems to have a higher dependency on the pixel value of the input.

        \begin{figure}[H]
            \centering
            \includegraphics[width=\textwidth]{Includes/5-source-noise-SNR.pdf}
            \caption{Comparison of the SNR expressed in dB of the low resolution images generated by the baseline and adapted degradation model.}
            \label{fig:5-source-noise-SNR}
        \end{figure}

        The observed effects support what is observed in the Fig. \ref{fig:5-source-domain-comparison}. 
        The adapted pipeline produces broader kernels and noise with more energy, compared to the baseline pipeline.
        This leads to more blurry and more noisy generated LR images. 
        The kernel imposes the diminishing of frequency components in the signal, and the noise degrades the ratio of clean signal energy in the image.
        Both components will create a more difficult scenario for the super resolution model, which will try to go back to the HR image from the generated LR image.

        \subsubsection{Low resolution images comparison}

        A quantitative analysis of the LR images obtained by the generator of each pipeline is performed. 
        Fig. \ref{fig:5-source-domain-lr-performance-scatterplot} shows 3 supervised performance metrics obtained by comparing the LR images obtained by the pipelines with the gaussian blurring + bicubic downsampling degradation.
        In this case, a consistent higher PSNR and SSIM means that the baseline-LR image is closer to the gaussian blurring + bicubic downsampling LR image than the one generated by the adapted pipeline. 
        A lower LPIPS means that even using perceptual metrics, the baseline-LR image is also closer.
        This is consistent with the results shown in Fig. \ref{fig:5-source_domain_sample}, where the adapted LR image is more blurry and noisy, suggesting that the unknown degradation is far from a baseline degradation model.
        
        \begin{figure}[H]
            \centering
            \includegraphics[width=\textwidth]{Includes/5-source-domain-lr-performance-scatterplot.pdf}
            \caption{Performance metrics between the LR images obtained by the pipelines vs the gaussian blurring + bicubic downsampling degradation.
                     On the left, the PSNR is displayed. On the middle and the right, SSIM and LPIPS are represented respectively.}
            \label{fig:5-source-domain-lr-performance-scatterplot}
        \end{figure}




        An alternative way to evaluate the differences in the degradations is by analyzing the frequency domain of the LR images.
        An analysis of the whole validation dataset is performed by calculating the FFT of each LR image and comparing them with the gaussian blurring + bicubic downsmapling degradation model.
        The results are displayed shown in Fig. \ref{fig:5-lr-images-fft-comparison}. 
        In (a) the log magnitude of the FFT across different spatial frequency values for the degraded images is shown. 
        The spatial frequency is obtained from the radial distance to the center of the FFT, as shown in \ref{subsubsec:frequency_domain_analysis}.
        In (b), the amplification of each generated LR image with respect to a simple gaussian blurring + downscaling is shown. 
        The results for the whole dataset show that the LR images generated by the adapted pipeline yield a reduction in the higher frequency components consistently across all samples, with a ± 1 standard deviation interval between -4 and -6 dB from between 0.3 and 0.7 cycles per 210m pixel.

        \begin{figure}[H]
            \centering
            \includegraphics[scale=0.5]{Includes/5-source-lr-amplification-statistics.pdf}
            \caption{Frequency domain analysis of the LR images obtained by applying different degradation models on the HR sample displayed in Fig. \ref{fig:5-source_domain_sample}.
                     In (a), the log of the magnitude of the FFT for the LR images is shown,
                     while in (b), the amplification with respect to a  simple gaussian blurring + downscaling is shown.
                     The painted area represents the ±1 standard deviation of the radial profiles and the amplification. }
            \label{fig:5-lr-images-fft-comparison}
        \end{figure}




        \subsubsection{Effects of the degradation model in SR}

        Another subject of interest is how the degradation model affects the performance of the super resolution process.
        Fig. \ref{fig:5-source-domain-comparison} shows the performance obtained by super resolving the output of each pipeline generator for the whole validation dataset.
        In the upper row (a), the corresponding SR model of each pipeline is used to obtain the super resolved images. 
        The performance, both in PSNR and SSIM, are very similar for both pipelines. The LPIPS shows a consistent behavior too.
        In the lower row (b), the SR model is discarded and a simple bicubic upsampling is used to super resolve the degraded images of each pipeline. 
        In this case, using the baseline LR version as input consistently yields better results than the adapted LR version, in all metrics.
        This suggests that the learned degradation model from FOREST-2 images loses more information than the baseline, resulting in a lower effective ground sampling distance than what was is specified in FOREST-2 fact sheet.
        Consistent with what was found in the frequency domain analysis observed in Fig. \ref{fig:5-source-sr-fft-comparison}, the SR model is able to recover most of the information, as the performance when employing the SR models is very similar. 
        
        \begin{figure}[H]
            \centering
            \includegraphics[width=\textwidth]{Includes/5-source-domain-comparison.png}
            \caption{Performance obtained by super resolving the degraded images coming out of the generator. 
                     In (a), the corresponding SR model of each pipeline is used. 
                     In (b), a simple bicubic upsampling is used to super resolve the degraded images. }
            \label{fig:5-source-domain-comparison}
        \end{figure}

        Fig \ref{fig:5-source-domain-comparison} proves the relevance of the domain gap in super resolution, the SR model is able to estimate the inverse of the degradation function, if given the correct data.
        The problem relies on that in most experiments, the wrong degradation is shown to the model, forcing it to learn the inverse of an incorrect function.  
        This plays an essential role when deploying super resolution model in real production environments, where the degradation model may not be known. 

    \subsection{Target domain}

        This subsection will show the results from the experiments performed on the target domain, which is the equivalent of the red arrows flow described in fig. \ref{fig:3-GAN-degradation-model}.
        In this case, the GAN trained for the degradation model is discarded and only the super resolution model is used.
        The input images are real FOREST-2 images, and the output images are super resolved versions of them. 
        Due to the unpaired nature of the dataset, the performance of the SR model can not be evaluated using metrics like PSNR and SSIM. 
        Other alternatives will be presented, and a qualitative analysis will be performed. 
        Additionally, a quantitative analysis will be discussed using a very small sample of paired data obtained by synchronizing the overpass of FOREST-2 with the route of ECOSTRESS.


        In Fig. \ref{fig:5-target_prediction_sample}, the super resolution models were used with a 264x264 pixels crop of a real FOREST-2 image as an input.
        The results show that the baseline model, trained with $\mathcal{D}_{\text{SF}-\text{SF}}$, has very similar results to bicubic upsampling.
        On the other side, the adapted model, trained using real FOREST images as the target domain ($\mathcal{D}_{\text{SF}-\text{RF}}$), is able to recover more details, producing sharper images.
        In the frequency domain, the effects of super resolution are clear, frequency components of interest are amplified compared to bicubic upsampling, without over-amplifying higher frequencies usually related to noise.
        
        


        \begin{figure}[H]
            \centering
            \includegraphics[scale=0.28]{Includes/5-target_prediction_sample.pdf}
            \caption{Super Resolved Forest-2 Scene using different SR models.
                     In the upper row, the image is displayed. A detailed zoom is displayed below. The bottom row shows the log magnitude of the FFT for the images.
                     The original image is displayed in the left, while the super resolved images are displayed afterwards.
                    }
            \label{fig:5-target_prediction_sample}
        \end{figure}

        % The results of Fig. \ref{fig:5-target_prediction_sample} with the theory and the results obtained in the source domain.
        % The super resolutions task is to estimate the inverse function of the degradation process. 
        % When the model is trained using an optimistic degradation process, the model is snot able to recover details from images generated by a more complex degradation process, like the real FOREST-2 images.
        % The lack of details in the baseline-SISR images is not because the model is not able to recover them, but because a more optimistic degradation model was used in training. 
        % This is an important result to drive the attention to the importance of the degradation model used in training, instead of focusing on more complex super resolution architectures.

        Fig. \ref{fig:5-target-amplification-statistics} shows a more detailed analysis of the frequency domain of the SR images obtained by applying different SR models to the whole FOREST-2 validation dataset.
        In (a),the log magnitude of the FFT for the SR images is displayed, adding a shade that represent the interval of ±1 standard deviations. 
        Up until 0.3 cycles per pixel, the adapted model has a higher log magnitude than the baseline SR model or bicubic upsampling, also staying slightly higher in high frequency components.
        As higher frequencies are related to noise and artifacts, this suggests that the adapted model is able to recover more details than the baseline model, while minimizing undesired components.
        The amplification plot of the SR models against bicubic upsampling shows the same behaviour in a more clear way. Between 0.1 and 0.25 cycles per pixel, the amplification peaks  between 6 and 8 dB on average with respect to bicubic, while the baseline model is between 0 and 2 dB.
        Such amplification, at a pixel size of 70m, corresponds to cycle frequencies between  300 $\frac{1}{m}$ and 700 $\frac{1}{m}$, which is consistent with the loss of components observed in \ref{fig:5-lr-images-fft-comparison}.
        The variability of the amplification allows to conclude that this amplification is consistently higher than the baseline-SISR along the dataset.
        On the other side, while the amplification is very similar in frequencies related to noise, the adapted model seems to step up a little bit compared to the baseline.  
        This suggests that the adapted model is able to recover details from real FOREST-2 images, amplifying frequencies of interest, at the cost of a small increase in the overall noise of the image.

        \begin{figure}[H]
            \centering
            \includegraphics[scale=0.5]{Includes/5-target-amplification-statistics.pdf}
            \caption{Frequency domain analysis of the SR images obtained by applying different SR models to the real FOREST-2 validation dataset.
            In (a), the log of the magnitude of the FFT for the SR images is shown,
            while in (b), the amplification with respect to a  simple bicubic upsampling is displayed.}
            \label{fig:5-target-amplification-statistics}
        \end{figure}


        In Fig. \ref{fig:6-target-gradient-analysis-image}, an example of the gradient analysis of the SR images is shown. 
        Compared to the baseline SISR model, the adapted model shows higher gradient magnitudes, suggesting that the adapted model is able to recover more details than the baseline model. 
        However, in the more dark sections of the gradient magnitude, some small background noise can be percieved, consistent with the results of the frequency domain analysis.

        \begin{figure}[H]
            \centering
            \includegraphics[scale=0.28]{Includes/6-target-gradient-analysis-image.pdf}
            \caption{Gradient analysis of the super resolved images using different SR models for scenes coming from the real FOREST-2 validation dataset.
                     In the upper row, the image is displayed. The gradients in the x and y direction ($G_x$ and $G_y$ respectiely) are displayed below.
                     the gradient magnitude $|G|$ is displayed in the bottom row.}
            \label{fig:6-target-gradient-analysis-image}
        \end{figure}

        Fig \ref{fig:5-gradient-histogram-validation-dataset} shows the distribution function of the gradient magnitudes of the whole validation dataset, estimated through a histogram.
        Both the adapted and the baseline model show a decrease in the number of pixels with low gradient magnitudes, suggesting that both models are able to recover more details than bicubic upsampling.
        However, the adapted model shows a higher number of pixels with high gradient magnitudes, implying that the adapted model is able to produce sharper edges than the baseline model.
        This is consistent with the observed results and the frequency domain analysis. 
        However, it is important to note that the gradient magnitude is not a good measure of the performance of the SR model, as it does not take into account the noise and artifacts that may be present in the image.
        It represents only a complementary way to understand the effects of the SR model.


        \begin{figure}[H]
            \centering
            \includegraphics[scale=0.4]{Includes/5-gradient-histogram-validation-dataset.pdf}
            \caption{Histogram of the gradient magnitude $|G|$ for the whole validation real FOREST-2 dataset.}
            \label{fig:5-gradient-histogram-validation-dataset}
        \end{figure}

    \subsection{The domain gap goes both ways}

         % Another example would be images taken from FOREST-2 in several years may not have the same distribution as current images, as the instruments may have degraded over time.

        % To simulate this situation, the model trained using real FOREST-2 images was employed to super-resolve synthetic FOREST images degraded using the baseline degradation model. The results, shown in Figs. \ref{fig:5-target-prediction-with-domain-gap} and \ref{fig:5-target-prediction-with-domain-gap-fft}, indicate the performance of the adapted model is catastrophic, producing several artifacts and yielding a PSNR difference of approximately 10dB, which represents a tenfold difference in terms of Mean Squared Error (MSE). This highlights the critical need for adaptable SR models that can effectively handle diverse and evolving real-world scenarios.


        The combination of the probabilistic degradation model and the SR model were proven helpful to bridge the domain gap and inprove the resolution of real FOREST-2 images.
        However, it is important to understand what happens when the target domain used in training does not match the conditions that will occur in the real world.
        While the common scenario is that the real degradation model is more complex than the one assumed in the dataset generation, the opposite can also occur.
        Assuming a more complex degradation model in the dataset could lead to LR images with more attenuation in higher frequency components, resulting in an SR model that "over-amplifies", producing noisy images with undesired artifacts.
        In this work, HR-LR pairs generated using a baseline degradation model exemplify an overly optimistic degradation scenario.
        When using the adapted SR model on these generated LR images, this scenario can be analyzed.
        As in this experiment the ground truth is known, the performance of the SR model can be evaluated using metrics like PSNR and SSIM.
        
        The results are shown in Figs. \ref{fig:5-target-prediction-with-domain-gap} and \ref{fig:5-target-prediction-with-domain-gap-fft}.
        The performance of the adapted model on images with an optimistic degradation model is catastrophic, producing several artifacts and yielding a PSNR difference of approximately 10dB, which represent a 10x difference in terms of MSE.

        \begin{figure}[H]
            \centering
            \includegraphics[scale=0.28]{Includes/5-target-prediction-with-domain-gap.pdf}
            \caption{Effects of using a model trained with on different domain than at inference time. 
                     When using an Synthetic FOREST image degraded with the baseline degradation model as an input, the model trained using real FOREST-2 data as the target domain generates several artifacts and underperforms severly in terms of PSNR. }
            \label{fig:5-target-prediction-with-domain-gap}
        \end{figure}

        In the frequency domain, the results  are shown in Fig. \ref{fig:5-target-prediction-with-domain-gap-fft}.  
        The adapted model adds amplification in the higher range of spatial frequency, related with noise and artifacts.
        The frequencies of interest are also amplified.
        This suggests that while the adapted model highlights edges and details, it also severely amplifies the noise and artifacts, resulting in a worse performance in terms of PSNR.
        

        \begin{figure}[H]
            \centering
            \includegraphics[scale=0.4]{Includes/5-target-prediction-with-domain-gap-fft.pdf}
            \caption{Effects of using a model trained with on different domain than at inference time. 
                     (a) shows the log magnitude of the radial average of the FFT for the SR images using different algorithms.
                     (b) shows the amplification with respect to bicubic interpolation.
                     }
            \label{fig:5-target-prediction-with-domain-gap-fft}
        \end{figure}


        The performance results in terms of different metrics are shown in Fig. \ref{fig:5-target-prediction-with-domain-gap-dataset}. 
        In the conditions described above, the adapted super resolution model underperforms severly in every considered metric.


        \begin{figure}[H]
            \centering
            \includegraphics[scale=0.38]{Includes/5-target-prediction-with-domain-gap-dataset.pdf}
            \caption{Performance obtained by super resolving the degraded synthetic FOREST images using different super resolution models.}
            \label{fig:5-target-prediction-with-domain-gap-dataset}
        \end{figure}
        
        
    This demonstrates that while this approach is very good to bridge a domain gap, it is not robust at all to domain shifts. 
    This limitation is in sync with what is found in the literature seen in \ref{subsubsec:implicit-modelling}, implicit modelling for blind super resolution using GANs are not able to generalize to arbitrary domains not seen in the target domain.

    \subsection{Domain gap assessment using non-referenced image quality assessment}

    As in the target domain the ground truth is not known due to the lack of a paired dataset, the performance of the SR model can not be evaluated using metrics like PSNR and SSIM.
    Non-referenced image quality assessment (NR-IQA) metrics can help to understand the relative performance of the SR models when arbitrary LR images are used as an input.
    
    The analysis was performed by taking the adapted and baseline SR models, trained on $\mathcal{D}_{\text{SF}-\text{RF}}$ and $\mathcal{D}_{\text{SF}-\text{SF}}$ respectively, and using them to super resolve synthetic degraded forest-2 images and real LR forest-2 images as an input.
    Then, the NIQE and BRISQUE scores are calculated.
    
    The results are shown in Fig. \ref{fig:5-target-iqa-results}.
    For both metrics, a large gap is observed between the adapted model and the rest when the input are real FOREST-2 data, suggesting that the adapted model is able to produce more natural images than the rest.
    This behaviour does not replicates when the input images come from $\mathcal{D}_{\text{SF}-\text{SF}}$.

    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.28]{Includes/5-target-iqa-results.pdf}
        \caption{Image quality assessment metrics for the different SR models using different datasets as input. 
                In both metrics, the lower the score, the better the image quality.}
        \label{fig:5-target-iqa-results}
    \end{figure}
    
    Moreover, for the adapted model, both metrics tend to get worse when the input images come from synthetic FOREST-2 images. The contrary happens for the rest of the models.
    This suggests that the SR model is able to produce more natural images only when the input images come from the same distribution as the target domain used in training.
    
    However, it is important to note that: 

    \begin{enumerate}
        \item NIQE and BRISQUE are calculated using a pre-trained model. The images used for the pre-training are not remote sensing images, and therefore, the results may not be representative. This could be circumvented by training a NIQE/BRISQUE model using with a more adequate dataset for the task.
        \item NIQE and BRISQUE are a measure of image quality and naturalness, not physical consistency or reconstruction fidelity.
    \end{enumerate}

    While the relative comparison of these results may help to understand the behaviour of the models, it is important to note that the results are not representative of their real world performance. 

        
\newpage
    