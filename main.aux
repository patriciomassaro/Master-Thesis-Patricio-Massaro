\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Storyline}{1}{subsection.1.1}\protected@file@percent }
\citation{zeyde2010single}
\citation{martin2001database}
\citation{valsesia2021permutation}
\citation{bashir2021comprehensive}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Wildfire monitoring using thermal remote sensing}{2}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Spatio-temporal trade-off}{2}{subsubsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Super resolution}{2}{section.2}\protected@file@percent }
\newlabel{sec:SR}{{2}{2}{Super resolution}{section.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of super resolution as an ill posed problem. A blurry picture of Barack Obama can be generated from an HR image of another person.\relax }}{2}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:2-SR-ill-posed}{{2.1}{2}{Example of super resolution as an ill posed problem. A blurry picture of Barack Obama can be generated from an HR image of another person.\relax }{figure.caption.3}{}}
\citation{martens2019superresolution}
\citation{MISR2007}
\citation{MISR2007}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}single-Image Super Resolution}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}SR Resnet}{3}{subsubsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Multi-Image Super Resolution}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Multi-spectral super resolution}{3}{subsubsection.2.2.1}\protected@file@percent }
\citation{myself2023}
\citation{lugmayr2020ntire}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Multi-image super resolution algorithms combine multiple low-resolution image acquisitions into a high-resolution image. Source: \cite  {MISR2007}\relax }}{4}{figure.caption.4}\protected@file@percent }
\newlabel{fig:2-MISR}{{2.2}{4}{Multi-image super resolution algorithms combine multiple low-resolution image acquisitions into a high-resolution image. Source: \cite {MISR2007}\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Importance of interframe correlation}{4}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}RAMS}{4}{subsubsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}The domain gap problem}{4}{subsection.2.3}\protected@file@percent }
\newlabel{subsec:domaingap}{{2.3}{4}{The domain gap problem}{subsection.2.3}{}}
\citation{liu2021blind}
\citation{liu2021blind}
\citation{liu2021blind}
\citation{liu2021blind}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Effects of different degradation models on one HR image. Source: \cite  {liu2021blind}\relax }}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:2-domain-gap}{{2.3}{5}{Effects of different degradation models on one HR image. Source: \cite {liu2021blind}\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Blind image Super Resolution}{5}{subsection.2.4}\protected@file@percent }
\citation{luo2022learning}
\citation{luo2022learning}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Domain interpretation of differences between non-blind and blind SR. Source: \cite  {liu2021blind}\relax }}{6}{figure.caption.6}\protected@file@percent }
\newlabel{fig:2-DomainGap}{{2.4}{6}{Domain interpretation of differences between non-blind and blind SR. Source: \cite {liu2021blind}\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces In Degradation-learning-based methods, adversarial training is used to encourage the degradation model to produce images in the same domain with the target domain (test images). Source \cite  {luo2022learning}.\relax }}{6}{figure.caption.7}\protected@file@percent }
\newlabel{fig:3-GAN-degradation-model}{{2.5}{6}{In Degradation-learning-based methods, adversarial training is used to encourage the degradation model to produce images in the same domain with the target domain (test images). Source \cite {luo2022learning}.\relax }{figure.caption.7}{}}
\citation{zhang2018residual}
\citation{ECOSTRESS2023INSTRUMENT}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{7}{section.3}\protected@file@percent }
\newlabel{sec:methodology}{{3}{7}{Methodology}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Baseline Degradation model}{7}{subsection.3.1}\protected@file@percent }
\newlabel{subsec:baseline_degradation_model}{{3.1}{7}{Baseline Degradation model}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Blurring Kernel}{7}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Example of kernels used in a stochastic degradation model. (a),(b) and (c) are generated using a symmetric variance on the x and y axis. (d) (e) and (f) are generated using an asymmetric variances, resulting in much more anisotropic kernels.\relax }}{7}{figure.caption.8}\protected@file@percent }
\newlabel{fig:4-degradation_kernels}{{3.1}{7}{Example of kernels used in a stochastic degradation model. (a),(b) and (c) are generated using a symmetric variance on the x and y axis. (d) (e) and (f) are generated using an asymmetric variances, resulting in much more anisotropic kernels.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Effects of different blurring kernels on the HR-LR generation. The upper row contains images generated using blurring kernels with symmetric distributions. The lower rows contains images generated using asymmetric distributions for the variances, resulting in highly anisotropic kernels.\relax }}{8}{figure.caption.9}\protected@file@percent }
\newlabel{fig:4-degradation_kernels}{{3.2}{8}{Effects of different blurring kernels on the HR-LR generation. The upper row contains images generated using blurring kernels with symmetric distributions. The lower rows contains images generated using asymmetric distributions for the variances, resulting in highly anisotropic kernels.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Radiometric error correction}{8}{subsubsection.3.1.2}\protected@file@percent }
\newlabel{eq:4-radiometric-error-correction}{{2}{8}{Radiometric error correction}{equation.3.2}{}}
\newlabel{eq:4-planck-derivative}{{3}{8}{Radiometric error correction}{equation.3.3}{}}
\citation{ledig2017photorealistic}
\citation{he2015deep}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Effects of different radiometric error corrections on the HR-LR generation.\relax }}{9}{figure.caption.10}\protected@file@percent }
\newlabel{fig:4-radiometric_noise_example}{{3.3}{9}{Effects of different radiometric error corrections on the HR-LR generation.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Models Architecture}{10}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}SRResNet}{10}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}RAMS}{10}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Probabilistic Degradation Model}{10}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces SADASDSA\relax }}{10}{figure.caption.11}\protected@file@percent }
\newlabel{fig:3-probabilistic-degradation-model}{{3.4}{10}{SADASDSA\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {paragraph}{Kernel Model}{10}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Noise Model}{10}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Discriminator}{10}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Referenced image quality metrics}{10}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}$L_2$ and $L_1$ Loss}{11}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Peak Signal-to-Noise Ratio (PSNR)}{11}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Structural Similarity Index (SSIM)}{11}{subsubsection.3.3.3}\protected@file@percent }
\citation{VGGnet}
\citation{martens2019superresolution}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.4}Learned perceptual image patch similarity (LPIPS)}{12}{subsubsection.3.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.5}Adjusting measures to a multi-image framework}{12}{subsubsection.3.3.5}\protected@file@percent }
\newlabel{eq:4_adjusted_metrics}{{9}{12}{Adjusting measures to a multi-image framework}{equation.3.9}{}}
\citation{niqe}
\citation{niqe}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Non-referenced Image quality metrics}{13}{subsection.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Workflow of a NR-IQA model.\relax }}{13}{figure.caption.15}\protected@file@percent }
\newlabel{fig:4-nr-iqa-workflow}{{3.5}{13}{Workflow of a NR-IQA model.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Naturalness Image Quality Evaluator (NIQE)}{13}{subsubsection.3.4.1}\protected@file@percent }
\citation{fuoli2021fourier}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Blind/Referenceless Image Spatial Quality Evaluator (BRISQUE)}{14}{subsubsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Frequency Domain Analysis}{14}{subsubsection.3.4.3}\protected@file@percent }
\newlabel{subsubsec:frequency_domain_analysis}{{3.4.3}{14}{Frequency Domain Analysis}{subsubsection.3.4.3}{}}
\citation{Sobel1990AnI3}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Steps of the frequency domain analysis. The Center image shows the log magnitude of the shifted FFT of a bicubic upsampled FOREST scene and an example of a radial profile, the average of all the points that have the same $r$ is calculated. The right image displays the log magnitude obtained for every radial profile, translated into spatial frequency. \relax }}{15}{figure.caption.16}\protected@file@percent }
\newlabel{fig:4-frequency-analysis}{{3.6}{15}{Steps of the frequency domain analysis. The Center image shows the log magnitude of the shifted FFT of a bicubic upsampled FOREST scene and an example of a radial profile, the average of all the points that have the same $r$ is calculated. The right image displays the log magnitude obtained for every radial profile, translated into spatial frequency. \relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4}Gradient Distribution analysis}{15}{subsubsection.3.4.4}\protected@file@percent }
\newlabel{eq:4-sobel-operators}{{12}{15}{Gradient Distribution analysis}{equation.3.12}{}}
\newlabel{eq:4-gradient_magnitude}{{13}{15}{Gradient Distribution analysis}{equation.3.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Steps to obtain a gradient magnitude density. Using the sobel operators, $G_x$ and $G_y$ are obtained from an image. The magnitude $|G|$ of each pixel is calculated using Eq. \ref {eq:4-gradient_magnitude}. The density can be estimated afterwards, using 100 bins in this case.\relax }}{16}{figure.caption.17}\protected@file@percent }
\newlabel{fig:4-gradient-analysis}{{3.7}{16}{Steps to obtain a gradient magnitude density. Using the sobel operators, $G_x$ and $G_y$ are obtained from an image. The magnitude $|G|$ of each pixel is calculated using Eq. \ref {eq:4-gradient_magnitude}. The density can be estimated afterwards, using 100 bins in this case.\relax }{figure.caption.17}{}}
\citation{ECOSTRESS2023}
\citation{PhyTIR2023}
\citation{ECOSTRESS2023}
\citation{AppEEARS2023}
\citation{AppEEARSAPI2023}
\citation{ECO1BMAPRAD2023}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiment Setup}{17}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Obtaining a high resolution dataset}{17}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}The ECOSTRESS mission}{17}{subsubsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Donwloading ECOSTRESS Scenes}{17}{subsubsection.4.1.2}\protected@file@percent }
\citation{ecostress_faq}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Wavelengths of the sensors in Ecostress and Forest satellites. The radiation spectrum of black-bodies at different temperatures are included for comparison.\relax }}{18}{figure.caption.18}\protected@file@percent }
\newlabel{fig:5-wavelength-comparison}{{4.1}{18}{Wavelengths of the sensors in Ecostress and Forest satellites. The radiation spectrum of black-bodies at different temperatures are included for comparison.\relax }{figure.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Requests configuration\relax }}{18}{table.caption.19}\protected@file@percent }
\newlabel{tab:5-scenes-characteristics}{{4.1}{18}{Requests configuration\relax }{table.caption.19}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Selecting the best scenes}{18}{subsubsection.4.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Location of the samples taken from ecostress.\relax }}{19}{figure.caption.20}\protected@file@percent }
\newlabel{fig:5-ecostress-map-location}{{4.2}{19}{Location of the samples taken from ecostress.\relax }{figure.caption.20}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Process applied to the scenes returned from one area request.\relax }}{19}{algorithm.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}Data Processing}{20}{subsubsection.4.1.4}\protected@file@percent }
\newlabel{tab:quality_classes}{{\caption@xref {tab:quality_classes}{ on input line 102}}{20}{Data Processing}{table.caption.21}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Fill Value and Data Quality Classes\relax }}{20}{table.caption.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.5}Obtaining FOREST-2 data}{20}{subsubsection.4.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Datasets}{20}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Data processing workflow\relax }}{21}{figure.caption.22}\protected@file@percent }
\newlabel{fig:5-data_processing_flow_chart}{{4.3}{21}{Data processing workflow\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Random crop processor\relax }}{21}{figure.caption.23}\protected@file@percent }
\newlabel{fig:5-random_crop_processor}{{4.4}{21}{Random crop processor\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Training: Synthetic Forest-Degraded Synthetic Forest}{21}{subsubsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Training: Synthetic FOREST - real FOREST (Unpaired)}{22}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Testing: Synthetic FOREST- real FOREST ( Paired)}{22}{subsubsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Training}{22}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Results and discussion}{23}{section.5}\protected@file@percent }
\newlabel{sec:results}{{5}{23}{Results and discussion}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Source domain}{23}{subsection.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Applying different degradation models on an HR sample. In the Baseline SISR, the target domain used for training the generator is composed of sysnthetic HR FOREST-2 images degraded using the model detailed in \ref {subsec:baseline_degradation_model}. In the adapted SISR, the target domain used for training the generator is composed of real FOREST-2 images.\relax }}{24}{figure.caption.24}\protected@file@percent }
\newlabel{fig:5-source_domain_sample}{{5.1}{24}{Applying different degradation models on an HR sample. In the Baseline SISR, the target domain used for training the generator is composed of sysnthetic HR FOREST-2 images degraded using the model detailed in \ref {subsec:baseline_degradation_model}. In the adapted SISR, the target domain used for training the generator is composed of real FOREST-2 images.\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Effects of the degradation model}{25}{subsubsection.5.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Performance obtained by super resolving the degraded synthetic FOREST images. In (a), the correspondingly trained SISR model is applied. In (b), a simple bicubic interpolation is used to super resolve the degraded images. \relax }}{25}{figure.caption.25}\protected@file@percent }
\newlabel{fig:5-source-domain-comparison}{{5.2}{25}{Performance obtained by super resolving the degraded synthetic FOREST images. In (a), the correspondingly trained SISR model is applied. In (b), a simple bicubic interpolation is used to super resolve the degraded images. \relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Frequency domain analysis of the LR images obtained by applying different degradation models on the HR sample displayed in Fig. \ref {fig:5-source_domain_sample}. In (a), the log of the magnitude of the FFT for the LR images is shown, while in (b), the amplification with respect to a simple gaussian blurring + downscaling is shown.\relax }}{26}{figure.caption.26}\protected@file@percent }
\newlabel{fig:5-lr-images-fft-comparison}{{5.3}{26}{Frequency domain analysis of the LR images obtained by applying different degradation models on the HR sample displayed in Fig. \ref {fig:5-source_domain_sample}. In (a), the log of the magnitude of the FFT for the LR images is shown, while in (b), the amplification with respect to a simple gaussian blurring + downscaling is shown.\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Target domain}{27}{subsection.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Super Resolved Forest-2 Scene using different SR models. In the upper row, the image is displayed. A detailed zoom is displayed below. The bottom row shows the log magnitude of the FFT for the images. The original image is displayed in the left, while the super resolved images are displayed afterwards. \relax }}{27}{figure.caption.27}\protected@file@percent }
\newlabel{fig:5-target_prediction_sample}{{5.4}{27}{Super Resolved Forest-2 Scene using different SR models. In the upper row, the image is displayed. A detailed zoom is displayed below. The bottom row shows the log magnitude of the FFT for the images. The original image is displayed in the left, while the super resolved images are displayed afterwards. \relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Frequency domain analysis of the SR images obtained by applying different SR models to the real FOREST-2 validation dataset. In (a), the log of the magnitude of the FFT for the SR images is shown, while in (b), the amplification with respect to a simple bicubic upsampling is displayed.\relax }}{29}{figure.caption.28}\protected@file@percent }
\newlabel{fig:5-target-amplification-statistics}{{5.5}{29}{Frequency domain analysis of the SR images obtained by applying different SR models to the real FOREST-2 validation dataset. In (a), the log of the magnitude of the FFT for the SR images is shown, while in (b), the amplification with respect to a simple bicubic upsampling is displayed.\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Gradient analysis of the super resolved images using different SR models for scenes coming from the real FOREST-2 validation dataset. In the upper row, the image is displayed. The gradients in the x and y direction ($G_x$ and $G_y$ respectiely) are displayed below. the gradient magnitude $|G|$ is displayed in the bottom row.\relax }}{30}{figure.caption.29}\protected@file@percent }
\newlabel{fig:6-target-gradient-analysis-image}{{5.6}{30}{Gradient analysis of the super resolved images using different SR models for scenes coming from the real FOREST-2 validation dataset. In the upper row, the image is displayed. The gradients in the x and y direction ($G_x$ and $G_y$ respectiely) are displayed below. the gradient magnitude $|G|$ is displayed in the bottom row.\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Histogram of the gradient magnitude $|G|$ for the whole validation real FOREST-2 dataset.\relax }}{31}{figure.caption.30}\protected@file@percent }
\newlabel{fig:5-gradient-histogram-validation-dataset}{{5.7}{31}{Histogram of the gradient magnitude $|G|$ for the whole validation real FOREST-2 dataset.\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Effects of the domain gap}{31}{subsection.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Effects of using a model trained with on different domain than at inference time. When using an Synthetic FOREST image degraded with the baseline degradation model as an input, the model trained using real FOREST-2 data as the target domain generates several artifacts and underperforms severly in terms of PSNR. \relax }}{32}{figure.caption.31}\protected@file@percent }
\newlabel{fig:5-target-prediction-with-domain-gap}{{5.8}{32}{Effects of using a model trained with on different domain than at inference time. When using an Synthetic FOREST image degraded with the baseline degradation model as an input, the model trained using real FOREST-2 data as the target domain generates several artifacts and underperforms severly in terms of PSNR. \relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Performance obtained by super resolving the degraded synthetic FOREST images using different super resolution models.\relax }}{32}{figure.caption.32}\protected@file@percent }
\newlabel{fig:5-target-prediction-with-domain-gap-dataset}{{5.9}{32}{Performance obtained by super resolving the degraded synthetic FOREST images using different super resolution models.\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Effects of using a model trained with on different domain than at inference time. (a) shows the log magnitude of the radial average of the FFT for the SR images using different algorithms. (b) shows the amplification with respect to bicubic interpolation \relax }}{33}{figure.caption.33}\protected@file@percent }
\newlabel{fig:5-target-prediction-with-domain-gap-fft}{{5.10}{33}{Effects of using a model trained with on different domain than at inference time. (a) shows the log magnitude of the radial average of the FFT for the SR images using different algorithms. (b) shows the amplification with respect to bicubic interpolation \relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Image quality assessment metrics for the different SR models using different datasets as input. In both metrics, the lower the score, the better the image quality.\relax }}{34}{figure.caption.34}\protected@file@percent }
\newlabel{fig:5-target-iqa-results}{{5.11}{34}{Image quality assessment metrics for the different SR models using different datasets as input. In both metrics, the lower the score, the better the image quality.\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}conclusions}{35}{section.6}\protected@file@percent }
\bibstyle{unsrt}
\bibdata{bibliography}
\bibcite{zeyde2010single}{1}
\bibcite{martin2001database}{2}
\bibcite{valsesia2021permutation}{3}
\bibcite{bashir2021comprehensive}{4}
\bibcite{martens2019superresolution}{5}
\bibcite{MISR2007}{6}
\bibcite{myself2023}{7}
\bibcite{lugmayr2020ntire}{8}
\bibcite{liu2021blind}{9}
\bibcite{luo2022learning}{10}
\bibcite{zhang2018residual}{11}
\bibcite{ECOSTRESS2023INSTRUMENT}{12}
\bibcite{ledig2017photorealistic}{13}
\bibcite{he2015deep}{14}
\bibcite{VGGnet}{15}
\bibcite{niqe}{16}
\bibcite{fuoli2021fourier}{17}
\bibcite{Sobel1990AnI3}{18}
\bibcite{ECOSTRESS2023}{19}
\bibcite{PhyTIR2023}{20}
\bibcite{AppEEARS2023}{21}
\bibcite{AppEEARSAPI2023}{22}
\bibcite{ECO1BMAPRAD2023}{23}
\bibcite{ecostress_faq}{24}
\gdef \@abspage@last{41}
